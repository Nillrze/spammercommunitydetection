{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I31dxA1kuLIf"
      },
      "source": [
        "## Download HoneyPot_dataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6_NFdsRHj-R",
        "outputId": "6a450629-438e-4fd3-875a-6a5c01235c63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-25 08:34:42--  http://infolab.tamu.edu/data/social_honeypot_icwsm_2011.zip\n",
            "Resolving infolab.tamu.edu (infolab.tamu.edu)... 45.55.217.29\n",
            "Connecting to infolab.tamu.edu (infolab.tamu.edu)|45.55.217.29|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://infolab.tamu.edu/data/social_honeypot_icwsm_2011.zip [following]\n",
            "--2022-06-25 08:34:43--  https://infolab.tamu.edu/data/social_honeypot_icwsm_2011.zip\n",
            "Connecting to infolab.tamu.edu (infolab.tamu.edu)|45.55.217.29|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 263659672 (251M) [application/zip]\n",
            "Saving to: ‘social_honeypot_icwsm_2011.zip’\n",
            "\n",
            "social_honeypot_icw 100%[===================>] 251.45M  13.4MB/s    in 23s     \n",
            "\n",
            "2022-06-25 08:35:08 (10.7 MB/s) - ‘social_honeypot_icwsm_2011.zip’ saved [263659672/263659672]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://infolab.tamu.edu/data/social_honeypot_icwsm_2011.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uocgtaPCIArO",
        "outputId": "dc400ec7-1b49-4310-9528-1827b6de38bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  social_honeypot_icwsm_2011.zip\n",
            "   creating: social_honeypot_icwsm_2011/\n",
            "  inflating: social_honeypot_icwsm_2011/content_polluters.txt  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/social_honeypot_icwsm_2011/\n",
            "  inflating: __MACOSX/social_honeypot_icwsm_2011/._content_polluters.txt  \n",
            "  inflating: social_honeypot_icwsm_2011/content_polluters_followings.txt  \n",
            "  inflating: __MACOSX/social_honeypot_icwsm_2011/._content_polluters_followings.txt  \n",
            "  inflating: social_honeypot_icwsm_2011/content_polluters_tweets.txt  \n",
            "  inflating: __MACOSX/social_honeypot_icwsm_2011/._content_polluters_tweets.txt  \n",
            "  inflating: social_honeypot_icwsm_2011/legitimate_users.txt  \n",
            "  inflating: __MACOSX/social_honeypot_icwsm_2011/._legitimate_users.txt  \n",
            "  inflating: social_honeypot_icwsm_2011/legitimate_users_followings.txt  \n",
            "  inflating: __MACOSX/social_honeypot_icwsm_2011/._legitimate_users_followings.txt  \n",
            "  inflating: social_honeypot_icwsm_2011/legitimate_users_tweets.txt  \n",
            "  inflating: __MACOSX/social_honeypot_icwsm_2011/._legitimate_users_tweets.txt  \n",
            "  inflating: social_honeypot_icwsm_2011/social_honeypot_icwsm_2011.pdf  \n",
            "  inflating: __MACOSX/social_honeypot_icwsm_2011/._social_honeypot_icwsm_2011.pdf  \n",
            "  inflating: __MACOSX/._social_honeypot_icwsm_2011  \n"
          ]
        }
      ],
      "source": [
        "!unzip social_honeypot_icwsm_2011.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaoK_feDImou",
        "outputId": "d994daba-0c94-44ec-f99f-1461f57a0c01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-plot\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.0.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.21.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.0->scikit-plot) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.1.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQB_WuGyICod"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re, string\n",
        "\n",
        "from scipy.stats import zscore\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import scikitplot as skplt\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9Yp-aVBIFFX"
      },
      "outputs": [],
      "source": [
        "\n",
        "def func(string):\n",
        "   return pd.Series(string.split(',')).astype(int)\n",
        "  \n",
        "  \n",
        "dfContent_polluters = pd.read_csv('social_honeypot_icwsm_2011/content_polluters.txt',sep='\\t', names=\n",
        "                 [\"UserID\",\"CreatedAt\",\"CollectedAt\",\"NumberOfFollowings\",\"NumberOfFollowers\",\n",
        "                  \"NumberOfTweets\",\"LengthOfScreenName\",\"LengthOfDescriptionInUserProfile\"],\n",
        "                parse_dates=[\"CreatedAt\",\"CollectedAt\"],index_col=0)\n",
        "\n",
        "dfContent_polluters_followings = pd.read_csv('social_honeypot_icwsm_2011/content_polluters_followings.txt',sep='\\t', names=\n",
        "                 [\"UserID\",\"SeriesOfNumberOfFollowings\"],converters={\"SeriesOfNumberOfFollowings\":func},index_col=0)\n",
        "\n",
        "dfContent_polluters_tweets = pd.read_csv('social_honeypot_icwsm_2011/content_polluters_tweets.txt',sep='\\t', names=\n",
        "                 [\"UserID\",\"TweetID\",\"Tweet\",\"CreatedAt\"], parse_dates=[\"CreatedAt\"],index_col=0)\n",
        "\n",
        "dfLegitimate_users = pd.read_csv('social_honeypot_icwsm_2011/legitimate_users.txt',sep='\\t', names=\n",
        "                 [\"UserID\",\"CreatedAt\",\"CollectedAt\",\"NumberOfFollowings\",\"NumberOfFollowers\",\n",
        "                  \"NumberOfTweets\",\"LengthOfScreenName\",\"LengthOfDescriptionInUserProfile\"],\n",
        "                parse_dates=[\"CreatedAt\",\"CollectedAt\"],index_col=0)\n",
        "\n",
        "dfLegitimate_users_followings = pd.read_csv('social_honeypot_icwsm_2011/legitimate_users_followings.txt',sep='\\t', names=\n",
        "                 [\"UserID\",\"SeriesOfNumberOfFollowings\"],converters={\"SeriesOfNumberOfFollowings\":func},index_col=0)\n",
        "\n",
        "\n",
        "dfLegitimate_users_tweets = pd.read_csv('social_honeypot_icwsm_2011/legitimate_users_tweets.txt',sep='\\t', names=\n",
        "                 [\"UserID\",\"TweetID\",\"Tweet\",\"CreatedAt\"], parse_dates=[\"CreatedAt\"],index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjOY06EwX8eD"
      },
      "outputs": [],
      "source": [
        "def get_user_id(data_frame) :\n",
        "  df = pd.DataFrame({\"UserID\":data_frame[\"UserID\"]})\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfS1TgRq1Igh"
      },
      "source": [
        "## \tFeaturse Extraction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjVXz1bp8igF"
      },
      "source": [
        "### 1 - The\tlongevity\tof\tthe\taccount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjEyR2sv8nJa"
      },
      "outputs": [],
      "source": [
        "\n",
        "def longevity(data_frame) :\n",
        "  df=pd.DataFrame({\"LongevityOfAccount\": (data_frame[\"CollectedAt\"]-data_frame[\"CreatedAt\"])/np.timedelta64(1, 'D')})\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9kbeN7ZCk3O"
      },
      "source": [
        "### 2 - Average Tweet Length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWixr1pnCskp"
      },
      "outputs": [],
      "source": [
        "def avgTweetLength(data_frame) :\n",
        "  dftemp=pd.DataFrame({\"AvgLengthTweets\": data_frame[\"Tweet\"].astype(str).apply(len)})\n",
        "  df = dftemp.groupby([\"UserID\"]).mean()\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWWkXa1mFyn6"
      },
      "source": [
        "### 3 -  |ReTweets |  /  |Tweets|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juRXEOslFyn9"
      },
      "outputs": [],
      "source": [
        "def existURL(tweet) :\n",
        "  if(len(re.findall('(RT|retweet|from|via)(?:\\b\\W*@(\\w+))+', str(tweet)))==0):\n",
        "    return 0;\n",
        "  else:\n",
        "    return 1;\n",
        "  \n",
        "def reTweetsFraction(data_frame) :\n",
        "  dftemp=pd.DataFrame({\"ReTweetFraction\": data_frame[\"Tweet\"].apply(existURL)})\n",
        "  df = dftemp.groupby([\"UserID\"]).mean()\n",
        "  return df\n",
        "# def nbrOfTweets(data_frame) :\n",
        "#   df = pd.DataFrame({\"NumberOfTweets\": data_frame[\"NumberOfTweets\"] })\n",
        "#   return df\n",
        "\n",
        "# def nbrOfReTweets(data_frame) :\n",
        "#   df = pd.DataFrame({\"NumberOfReTweets\": data_frame[\"NumberOfReTweets\"] })\n",
        "#   return df\n",
        "  \n",
        "# def reTweetsFraction(data_frame) :\n",
        "#   dftemp=pd.DataFrame({\"ReTweetFraction\": (nbrOfReTweets(data_frame) / nbrOfTweets(data_frame)) })\n",
        "#   df = dftemp.groupby([\"UserID\"]).mean()\n",
        "#   return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gF76X4KO3-h7"
      },
      "source": [
        "### 4 - |Tweets with URL|  /  |Tweets|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxLzAKw54Ebf"
      },
      "outputs": [],
      "source": [
        "def existURL(tweet) :\n",
        "  if(len(re.findall('https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+', str(tweet)))==0):\n",
        "    return 0;\n",
        "  else:\n",
        "    return 1;\n",
        "  \n",
        "def URLsPerTweets(data_frame) :\n",
        "  dftemp=pd.DataFrame({\"AvgTweetsWithURL\": data_frame[\"Tweet\"].apply(existURL)})\n",
        "  df = dftemp.groupby([\"UserID\"]).mean()\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ8OT2dKBEBM"
      },
      "source": [
        "### 5 - Average time between 2 consecutives tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wphcuK8nBRqy"
      },
      "outputs": [],
      "source": [
        "def avgTimeBetween2Tweets(data_frame):\n",
        "  temp=pd.DataFrame({\"CreatedAt\":data_frame[\"CreatedAt\"]}).sort_values(by=['UserID','CreatedAt'])\n",
        "  dftemp=pd.DataFrame({\"PreviousTweet\":temp.groupby(['UserID']).apply(lambda x:x)['CreatedAt'],\n",
        "                       \"NextTweet\":temp.groupby(['UserID']).shift(-1)['CreatedAt']})\n",
        "  df=pd.DataFrame({\"AvgMinutesBetween2Tweets\": (dftemp[\"NextTweet\"]-dftemp[\"PreviousTweet\"]) / np.timedelta64(1, 'm')})\n",
        "  df=df.groupby([\"UserID\"]).mean()\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQK3aUtFJkH6"
      },
      "source": [
        "### 6 -  Followings / Followers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ow-XrfbJkH7"
      },
      "outputs": [],
      "source": [
        "def fractionFF(data_frame) :\n",
        "  df = pd.DataFrame({\"RatioFollowings/Followers\": (data_frame[\"NumberOfFollowings\"] / data_frame[\"NumberOfFollowers\"]) })\n",
        "  return df "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCQZa6He9r30"
      },
      "source": [
        "### 7 - The standard\tdeviation\tof unique\tnumerical\tIDs\tof following"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P183tuDI9z-9"
      },
      "outputs": [],
      "source": [
        "def std(x):\n",
        "  return x.std()\n",
        "\n",
        "def followingsSTD(data_frame) :\n",
        "  df = pd.DataFrame({\"STDOfUniqueFollowers\":data_frame[\"SeriesOfNumberOfFollowings\"].apply(std)})\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idQPTBe6lB2Q"
      },
      "source": [
        "### 8 - Number of tweets / day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJII29cslFrL"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def numberOfTweetsPerDay(data_frame) :\n",
        "  dftemp = pd.DataFrame({\"CreatedAt\":data_frame[\"CreatedAt\"].dt.date})\n",
        "  query=dftemp.groupby([\"UserID\",\"CreatedAt\"]).size()\n",
        "  query2=query.groupby([\"UserID\"]).mean().reset_index(name='0')\n",
        "  df = pd.DataFrame({\"UserID\":query2[\"UserID\"],\"NumberOfTweetsPerDay\":query2[\"0\"]})\n",
        "  df=df.set_index(\"UserID\")\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5f-FJpe38sL"
      },
      "source": [
        "### 9 - Average mentions / Tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OR9sWj6Q4ADJ"
      },
      "outputs": [],
      "source": [
        "def countM(tweet):\n",
        "  return len(re.findall('\\s([@#][\\w_-]+)', str(tweet)))\n",
        "\n",
        "def mentionsPerTweets(data_frame):\n",
        "  dftemp=pd.DataFrame({\"AvgMentionsPerTweet\": data_frame[\"Tweet\"].apply(countM)})\n",
        "  df = dftemp.groupby([\"UserID\"]).mean()\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zMbjl2NoI3b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_mKWDB19PrD"
      },
      "source": [
        "### 4 - Numbers of followings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USw4CtGy9Ug9"
      },
      "outputs": [],
      "source": [
        "def nbrFollowings(data_frame) :\n",
        "  df = pd.DataFrame({\"NumberOfFollowings\":data_frame[\"NumberOfFollowings\"]})\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN28xtJe9hH1"
      },
      "source": [
        "### 5 - Numbers of followers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tq1BfE0S9jru"
      },
      "outputs": [],
      "source": [
        "def nbrFollowers(data_frame) :\n",
        "  df = pd.DataFrame({\"NumberOfFollowers\":data_frame[\"NumberOfFollowers\"]})\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pddFk6Ix6D9"
      },
      "outputs": [],
      "source": [
        "# first_features_polluters=pd.concat([longevity(dfContent_polluters),\n",
        "#                                     fractionFF(dfContent_polluters),\n",
        "#                                     reTweetsFraction(dfContent_polluters_tweets),\n",
        "#                                     avgTweetLength(dfContent_polluters_tweets),\n",
        "#                                     URLsPerTweets(dfContent_polluters_tweets),\n",
        "#                                     avgTimeBetween2Tweets(dfContent_polluters_tweets)],axis=1)\n",
        "\n",
        "# first_features_legitimate=pd.concat([longevity(dfLegitimate_users),\n",
        "#                                     fractionFF(dfLegitimate_users),\n",
        "#                                     reTweetsFraction(dfLegitimate_users_tweets),\n",
        "#                                     avgTweetLength(dfLegitimate_users_tweets),\n",
        "#                                     URLsPerTweets(dfLegitimate_users_tweets),\n",
        "#                                     avgTimeBetween2Tweets(dfLegitimate_users_tweets)],axis=1)\n",
        "\n",
        "first_features_polluters=pd.concat([longevity(dfContent_polluters),\n",
        "                                    # fractionFF(dfContent_polluters),\n",
        "                                    nbrFollowings(dfContent_polluters), #nbrFollowers(dfContent_polluters),\n",
        "                                    followingsSTD(dfContent_polluters_followings),\n",
        "                                    mentionsPerTweets(dfContent_polluters_tweets),\n",
        "                                    reTweetsFraction(dfContent_polluters_tweets),\n",
        "                                    avgTweetLength(dfContent_polluters_tweets),\n",
        "                                    URLsPerTweets(dfContent_polluters_tweets),\n",
        "                                    numberOfTweetsPerDay(dfContent_polluters_tweets),\n",
        "                                    avgTimeBetween2Tweets(dfContent_polluters_tweets)],axis=1)\n",
        "\n",
        "first_features_legitimate=pd.concat([longevity(dfLegitimate_users),\n",
        "                                    # fractionFF(dfLegitimate_users),\n",
        "                                    nbrFollowings(dfLegitimate_users),#nbrFollowers(dfLegitimate_users),\n",
        "                                    followingsSTD(dfLegitimate_users_followings),\n",
        "                                    mentionsPerTweets(dfLegitimate_users_tweets),\n",
        "                                    reTweetsFraction(dfLegitimate_users_tweets),\n",
        "                                    avgTweetLength(dfLegitimate_users_tweets),\n",
        "                                    URLsPerTweets(dfLegitimate_users_tweets),\n",
        "                                    numberOfTweetsPerDay(dfLegitimate_users_tweets),\n",
        "                                    avgTimeBetween2Tweets(dfLegitimate_users_tweets)],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8kIDaw_MVIL"
      },
      "outputs": [],
      "source": [
        "first_features_polluters_wtRT=pd.concat([longevity(dfContent_polluters),\n",
        "                                    # followingsSTD(dfContent_polluters_followings),\n",
        "                                    mentionsPerTweets(dfContent_polluters_tweets),\n",
        "                                    avgTweetLength(dfContent_polluters_tweets),\n",
        "                                    URLsPerTweets(dfContent_polluters_tweets),\n",
        "                                    numberOfTweetsPerDay(dfContent_polluters_tweets),\n",
        "                                    avgTimeBetween2Tweets(dfContent_polluters_tweets)],axis=1)\n",
        "\n",
        "first_features_legitimate_wtRT=pd.concat([longevity(dfLegitimate_users),\n",
        "                                    # followingsSTD(dfLegitimate_users_followings),\n",
        "                                    mentionsPerTweets(dfLegitimate_users_tweets),\n",
        "                                    avgTweetLength(dfLegitimate_users_tweets),\n",
        "                                    URLsPerTweets(dfLegitimate_users_tweets),\n",
        "                                    numberOfTweetsPerDay(dfLegitimate_users_tweets),\n",
        "                                    avgTimeBetween2Tweets(dfLegitimate_users_tweets)],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZIByvOcKcJ_"
      },
      "source": [
        "## Label Honey Pot dataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yL5luRYHKVC7"
      },
      "outputs": [],
      "source": [
        "data_set_polluters = first_features_polluters\n",
        "data_set_legitimate = first_features_legitimate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJxi5sybMa0M"
      },
      "outputs": [],
      "source": [
        "data_set_polluters_wtRT = first_features_polluters_wtRT\n",
        "data_set_legitimate_wtRT = first_features_legitimate_wtRT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "652uw2NCKZUw"
      },
      "outputs": [],
      "source": [
        "data_set_polluters.insert(0,\"Class\",1)\n",
        "data_set_legitimate.insert(0,\"Class\",0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EbNcngDMe2E"
      },
      "outputs": [],
      "source": [
        "data_set_polluters_wtRT.insert(0,\"Class\",1)\n",
        "data_set_legitimate_wtRT.insert(0,\"Class\",0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa038FCbRoMg"
      },
      "source": [
        "## Clean Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzmrzdH3d2Gg"
      },
      "outputs": [],
      "source": [
        "def attributesOfUniqueValues(data_set_users) :\n",
        "  list=[]\n",
        "  for col in data_set_users.columns:\n",
        "    if (data_set_users[col]==data_set_users[col].iloc[0]).all == True:\n",
        "      list.append(col)\n",
        "  return data_set_users.drop(list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6M7jmkyd_Il"
      },
      "outputs": [],
      "source": [
        "def duplicateRows(data_set_users):\n",
        "  return data_set_users.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jt7MBNHJeBkx"
      },
      "outputs": [],
      "source": [
        "def missingValues(data_set_users):\n",
        "  valuesReplaced = data_set_users.replace([np.inf,-np.inf],np.nan)\n",
        "  valuesReplaced.fillna(0,inplace=True)\n",
        "  return valuesReplaced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "338FQjojeHJV"
      },
      "outputs": [],
      "source": [
        "def shiftCol(data_set_users):\n",
        "  df=data_set_users.drop([\"Class\"],axis=1)\n",
        "  # df=df.apply(zscore)\n",
        "  df[\"Class\"]=data_set_users[\"Class\"]\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOLtAYmVeJWN"
      },
      "outputs": [],
      "source": [
        "data_set_polluters=attributesOfUniqueValues(data_set_polluters)\n",
        "data_set_polluters=duplicateRows(data_set_polluters)\n",
        "data_set_polluters=missingValues(data_set_polluters)\n",
        "data_set_polluters=shiftCol(data_set_polluters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXPRTaUKNRBv"
      },
      "outputs": [],
      "source": [
        "data_set_legitimate=attributesOfUniqueValues(data_set_legitimate)\n",
        "data_set_legitimate=duplicateRows(data_set_legitimate)\n",
        "data_set_legitimate=missingValues(data_set_legitimate)\n",
        "data_set_legitimate=shiftCol(data_set_legitimate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BP_YIDvr1tig"
      },
      "outputs": [],
      "source": [
        "data_set=pd.concat([data_set_polluters,data_set_legitimate])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "J8YYuB2LMkF0",
        "outputId": "2b278942-8e17-41a5-dffe-d795a52ca9f7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c0539429-28b1-4dce-8b8e-68d555e72d77\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LongevityOfAccount</th>\n",
              "      <th>AvgMentionsPerTweet</th>\n",
              "      <th>AvgLengthTweets</th>\n",
              "      <th>AvgTweetsWithURL</th>\n",
              "      <th>NumberOfTweetsPerDay</th>\n",
              "      <th>AvgMinutesBetween2Tweets</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>UserID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6301</th>\n",
              "      <td>1217.812905</td>\n",
              "      <td>0.140000</td>\n",
              "      <td>90.555000</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>492.219765</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10836</th>\n",
              "      <td>1329.539931</td>\n",
              "      <td>0.464646</td>\n",
              "      <td>84.686869</td>\n",
              "      <td>0.601010</td>\n",
              "      <td>2.224719</td>\n",
              "      <td>4396.333756</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10997</th>\n",
              "      <td>1272.640301</td>\n",
              "      <td>0.791878</td>\n",
              "      <td>98.974619</td>\n",
              "      <td>0.263959</td>\n",
              "      <td>49.250000</td>\n",
              "      <td>28.432738</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>633293</th>\n",
              "      <td>1105.971852</td>\n",
              "      <td>0.290000</td>\n",
              "      <td>74.875000</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>10.526316</td>\n",
              "      <td>125.861139</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>717883</th>\n",
              "      <td>1105.341435</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>99.910000</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>9.523810</td>\n",
              "      <td>218.854020</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93390990</th>\n",
              "      <td>0.053056</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>58.400000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>15.833333</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93402679</th>\n",
              "      <td>0.005995</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93419256</th>\n",
              "      <td>0.005069</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93426370</th>\n",
              "      <td>0.006146</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93442002</th>\n",
              "      <td>0.006562</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41494 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0539429-28b1-4dce-8b8e-68d555e72d77')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c0539429-28b1-4dce-8b8e-68d555e72d77 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c0539429-28b1-4dce-8b8e-68d555e72d77');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          LongevityOfAccount  AvgMentionsPerTweet  AvgLengthTweets  \\\n",
              "UserID                                                               \n",
              "6301             1217.812905             0.140000        90.555000   \n",
              "10836            1329.539931             0.464646        84.686869   \n",
              "10997            1272.640301             0.791878        98.974619   \n",
              "633293           1105.971852             0.290000        74.875000   \n",
              "717883           1105.341435             0.080000        99.910000   \n",
              "...                      ...                  ...              ...   \n",
              "93390990            0.053056             0.800000        58.400000   \n",
              "93402679            0.005995             0.000000        10.000000   \n",
              "93419256            0.005069             0.000000        23.000000   \n",
              "93426370            0.006146             0.000000       112.000000   \n",
              "93442002            0.006562             0.000000        22.000000   \n",
              "\n",
              "          AvgTweetsWithURL  NumberOfTweetsPerDay  AvgMinutesBetween2Tweets  \\\n",
              "UserID                                                                       \n",
              "6301              0.630000              4.000000                492.219765   \n",
              "10836             0.601010              2.224719               4396.333756   \n",
              "10997             0.263959             49.250000                 28.432738   \n",
              "633293            0.320000             10.526316                125.861139   \n",
              "717883            0.680000              9.523810                218.854020   \n",
              "...                    ...                   ...                       ...   \n",
              "93390990          0.800000              5.000000                 15.833333   \n",
              "93402679          0.000000              1.000000                  0.000000   \n",
              "93419256          0.000000              1.000000                  0.000000   \n",
              "93426370          0.000000              1.000000                  0.000000   \n",
              "93442002          0.000000              1.000000                  0.000000   \n",
              "\n",
              "          Class  \n",
              "UserID           \n",
              "6301          1  \n",
              "10836         1  \n",
              "10997         1  \n",
              "633293        1  \n",
              "717883        1  \n",
              "...         ...  \n",
              "93390990      0  \n",
              "93402679      0  \n",
              "93419256      0  \n",
              "93426370      0  \n",
              "93442002      0  \n",
              "\n",
              "[41494 rows x 7 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_set_polluters_wtRT=attributesOfUniqueValues(data_set_polluters_wtRT)\n",
        "data_set_polluters_wtRT=duplicateRows(data_set_polluters_wtRT)\n",
        "data_set_polluters_wtRT=missingValues(data_set_polluters_wtRT)\n",
        "data_set_polluters_wtRT=shiftCol(data_set_polluters_wtRT)\n",
        "\n",
        "data_set_legitimate_wtRT=attributesOfUniqueValues(data_set_legitimate_wtRT)\n",
        "data_set_legitimate_wtRT=duplicateRows(data_set_legitimate_wtRT)\n",
        "data_set_legitimate_wtRT=missingValues(data_set_legitimate_wtRT)\n",
        "data_set_legitimate_wtRT=shiftCol(data_set_legitimate_wtRT)\n",
        "\n",
        "data_set_wtRT=pd.concat([data_set_polluters_wtRT,data_set_legitimate_wtRT])\n",
        "\n",
        "data_set_wtRT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "b26NFDUtiOy7",
        "outputId": "a63c7b6b-c8cf-4521-c15a-dde08b482868"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c670652a-afb6-46f9-94c3-e462c795e813\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LongevityOfAccount</th>\n",
              "      <th>NumberOfFollowings</th>\n",
              "      <th>STDOfUniqueFollowers</th>\n",
              "      <th>AvgMentionsPerTweet</th>\n",
              "      <th>ReTweetFraction</th>\n",
              "      <th>AvgLengthTweets</th>\n",
              "      <th>AvgTweetsWithURL</th>\n",
              "      <th>NumberOfTweetsPerDay</th>\n",
              "      <th>AvgMinutesBetween2Tweets</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>UserID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6301</th>\n",
              "      <td>1217.812905</td>\n",
              "      <td>3269</td>\n",
              "      <td>189.834956</td>\n",
              "      <td>0.140000</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>90.555000</td>\n",
              "      <td>0.630000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>492.219765</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10836</th>\n",
              "      <td>1329.539931</td>\n",
              "      <td>1949</td>\n",
              "      <td>11.384581</td>\n",
              "      <td>0.464646</td>\n",
              "      <td>0.601010</td>\n",
              "      <td>84.686869</td>\n",
              "      <td>0.601010</td>\n",
              "      <td>2.224719</td>\n",
              "      <td>4396.333756</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10997</th>\n",
              "      <td>1272.640301</td>\n",
              "      <td>1119</td>\n",
              "      <td>859.067567</td>\n",
              "      <td>0.791878</td>\n",
              "      <td>0.263959</td>\n",
              "      <td>98.974619</td>\n",
              "      <td>0.263959</td>\n",
              "      <td>49.250000</td>\n",
              "      <td>28.432738</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>633293</th>\n",
              "      <td>1105.971852</td>\n",
              "      <td>2174</td>\n",
              "      <td>284.877349</td>\n",
              "      <td>0.290000</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>74.875000</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>10.526316</td>\n",
              "      <td>125.861139</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>717883</th>\n",
              "      <td>1105.341435</td>\n",
              "      <td>7731</td>\n",
              "      <td>114.229063</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>99.910000</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>9.523810</td>\n",
              "      <td>218.854020</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93390990</th>\n",
              "      <td>0.053056</td>\n",
              "      <td>5</td>\n",
              "      <td>0.501015</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>58.400000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>15.833333</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93402679</th>\n",
              "      <td>0.005995</td>\n",
              "      <td>20</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93419256</th>\n",
              "      <td>0.005069</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93426370</th>\n",
              "      <td>0.006146</td>\n",
              "      <td>20</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93442002</th>\n",
              "      <td>0.006562</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41499 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c670652a-afb6-46f9-94c3-e462c795e813')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c670652a-afb6-46f9-94c3-e462c795e813 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c670652a-afb6-46f9-94c3-e462c795e813');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          LongevityOfAccount  NumberOfFollowings  STDOfUniqueFollowers  \\\n",
              "UserID                                                                   \n",
              "6301             1217.812905                3269            189.834956   \n",
              "10836            1329.539931                1949             11.384581   \n",
              "10997            1272.640301                1119            859.067567   \n",
              "633293           1105.971852                2174            284.877349   \n",
              "717883           1105.341435                7731            114.229063   \n",
              "...                      ...                 ...                   ...   \n",
              "93390990            0.053056                   5              0.501015   \n",
              "93402679            0.005995                  20              0.000000   \n",
              "93419256            0.005069                   0              0.000000   \n",
              "93426370            0.006146                  20              0.000000   \n",
              "93442002            0.006562                   1              0.000000   \n",
              "\n",
              "          AvgMentionsPerTweet  ReTweetFraction  AvgLengthTweets  \\\n",
              "UserID                                                            \n",
              "6301                 0.140000         0.630000        90.555000   \n",
              "10836                0.464646         0.601010        84.686869   \n",
              "10997                0.791878         0.263959        98.974619   \n",
              "633293               0.290000         0.320000        74.875000   \n",
              "717883               0.080000         0.680000        99.910000   \n",
              "...                       ...              ...              ...   \n",
              "93390990             0.800000         0.800000        58.400000   \n",
              "93402679             0.000000         0.000000        10.000000   \n",
              "93419256             0.000000         0.000000        23.000000   \n",
              "93426370             0.000000         0.000000       112.000000   \n",
              "93442002             0.000000         0.000000        22.000000   \n",
              "\n",
              "          AvgTweetsWithURL  NumberOfTweetsPerDay  AvgMinutesBetween2Tweets  \\\n",
              "UserID                                                                       \n",
              "6301              0.630000              4.000000                492.219765   \n",
              "10836             0.601010              2.224719               4396.333756   \n",
              "10997             0.263959             49.250000                 28.432738   \n",
              "633293            0.320000             10.526316                125.861139   \n",
              "717883            0.680000              9.523810                218.854020   \n",
              "...                    ...                   ...                       ...   \n",
              "93390990          0.800000              5.000000                 15.833333   \n",
              "93402679          0.000000              1.000000                  0.000000   \n",
              "93419256          0.000000              1.000000                  0.000000   \n",
              "93426370          0.000000              1.000000                  0.000000   \n",
              "93442002          0.000000              1.000000                  0.000000   \n",
              "\n",
              "          Class  \n",
              "UserID           \n",
              "6301          1  \n",
              "10836         1  \n",
              "10997         1  \n",
              "633293        1  \n",
              "717883        1  \n",
              "...         ...  \n",
              "93390990      0  \n",
              "93402679      0  \n",
              "93419256      0  \n",
              "93426370      0  \n",
              "93442002      0  \n",
              "\n",
              "[41499 rows x 10 columns]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7xWW1lZiTWP"
      },
      "outputs": [],
      "source": [
        "X=data_set.drop(['Class'],axis=1)\n",
        "X=X.values\n",
        "Y=data_set[\"Class\"].values\n",
        "train, test, target, trueResult = train_test_split(X, Y, test_size=0.3, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twXugbATMyVV"
      },
      "outputs": [],
      "source": [
        "X_wtRT=data_set_wtRT.drop(['Class'],axis=1)\n",
        "X_wtRT=X_wtRT.values\n",
        "Y_wtRT=data_set_wtRT[\"Class\"].values\n",
        "train_wtRT, test_wtRT, target_wtRT, trueResult_wtRT = train_test_split(X_wtRT, Y_wtRT, test_size=0.3, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxDrP3b2kqR9"
      },
      "outputs": [],
      "source": [
        "# shuffle = np.random.permutation(60000)\n",
        "# train, target = train[shuffle], target[shuffle]\n",
        "\n",
        "# train_wtRT, target_wtRT = train_wtRT[shuffle], target_wtRT[shuffle]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PjyovZtN0C2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UozQZfhgiogg",
        "outputId": "73074913-5ce0-41b5-92a0-b7747062880a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[7.67862269e+00, 5.48000000e+02, 3.63368211e+02, ...,\n",
              "        1.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
              "       [3.53187488e+02, 2.14000000e+02, 2.08869679e+00, ...,\n",
              "        2.55000000e-01, 1.33333333e+01, 1.12214489e+02],\n",
              "       [3.51044236e+02, 4.68300000e+03, 2.35307987e+02, ...,\n",
              "        2.95000000e-01, 2.70270270e+00, 7.30171692e+02],\n",
              "       ...,\n",
              "       [3.12887222e+02, 1.88100000e+03, 3.06642257e+01, ...,\n",
              "        1.10000000e-01, 1.66666667e+01, 8.40231156e+01],\n",
              "       [8.59500347e+01, 3.65000000e+02, 2.31430122e-01, ...,\n",
              "        8.88888889e-01, 4.15384615e+00, 2.17179277e+03],\n",
              "       [1.55452350e+02, 1.80000000e+02, 5.00919981e-01, ...,\n",
              "        8.75000000e-01, 2.66666667e+00, 2.00476262e+04]])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNxc_dNxio43",
        "outputId": "da6ce83c-7edf-4f3d-fe0b-829f687e23f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 1, ..., 1, 1, 0])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AszeLilzV5HZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J13NsU82yZv-"
      },
      "source": [
        "**Application des Algorithmes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmThtrw8krNn"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Decision Tree\n",
        "# decisionTree = DecisionTreeClassifier(random_state=0)\n",
        "# decisionTree.fit(train, target)\n",
        "# predictedAD = decisionTree.predict(test)\n",
        "# probasAD = decisionTree.predict_proba(test)\n",
        "\n",
        "# # Random Forest\n",
        "# randomForest = RandomForestClassifier(n_estimators=100)\n",
        "# randomForest.fit(train, target)\n",
        "# predictedRF = randomForest.predict(test)\n",
        "# probasRF = randomForest.predict_proba(test)\n",
        "\n",
        "# # Naive Bayes\n",
        "# gnb = GaussianNB()\n",
        "# gnb.fit(train, target)\n",
        "# predictedNB = gnb.predict(test)\n",
        "# probasNB = gnb.predict_proba(test)\n",
        "\n",
        "# # # SVM linear\n",
        "# # svm = SVC(kernel='linear',probability=True)\n",
        "# # svm.fit(train, target)\n",
        "# # predictedSVM = svm.predict(test)\n",
        "# # probasSVM = svm.predict_proba(test)\n",
        "\n",
        "# # # SVM sigmoid\n",
        "# # svmS = SVC(kernel='sigmoid',probability=True)\n",
        "# # svmS.fit(train, target)\n",
        "# # predictedSVMS = svmS.predict(test)\n",
        "# # probasSVMS = svmS.predict_proba(test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ag2NXo4eaglf"
      },
      "outputs": [],
      "source": [
        "\n",
        "# from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# # KNN  \n",
        "# knn = KNeighborsClassifier(n_neighbors=5)\n",
        "# knn.fit(train, target)\n",
        "# predictedknn = knn.predict(test)\n",
        "# probasknn = knn.predict_proba(test)\n",
        "\n",
        "# # KNN  _wtRT\n",
        "# knn_wtRT = KNeighborsClassifier(n_neighbors=5)\n",
        "# knn_wtRT.fit(train_wtRT, target_wtRT)\n",
        "# predictedknn_wtRT = knn_wtRT.predict(test_wtRT)\n",
        "# probasknn_wtRT = knn_wtRT.predict_proba(test_wtRT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4-qMwYPALQf"
      },
      "outputs": [],
      "source": [
        "# # Decision Tree _wtRT\n",
        "# decisionTree_wtRT = DecisionTreeClassifier(random_state=0)\n",
        "# decisionTree_wtRT.fit(train_wtRT, target_wtRT)\n",
        "# predictedAD_wtRT = decisionTree_wtRT.predict(test_wtRT)\n",
        "# probasAD_wtRT = decisionTree_wtRT.predict_proba(test_wtRT)\n",
        "\n",
        "# # Random Forest _wtRT\n",
        "# randomForest_wtRT = RandomForestClassifier(n_estimators=100)\n",
        "# randomForest_wtRT.fit(train_wtRT, target_wtRT)\n",
        "# predictedRF_wtRT = randomForest_wtRT.predict(test_wtRT)\n",
        "# probasRF_wtRT = randomForest_wtRT.predict_proba(test_wtRT)\n",
        "\n",
        "# # Naive Bayes _wtRT\n",
        "# gnb_wtRT = GaussianNB()\n",
        "# gnb_wtRT.fit(train_wtRT, target_wtRT)\n",
        "# predictedNB_wtRT = gnb_wtRT.predict(test_wtRT)\n",
        "# probasNB_wtRT = gnb_wtRT.predict_proba(test_wtRT)\n",
        "\n",
        "# # # SVM linear _wtRT\n",
        "# # svm_wtRT = SVC(kernel='linear',probability=True)\n",
        "# # svm_wtRT.fit(train_wtRT, target_wtRT)\n",
        "# # predictedSVM_wtRT = svm.predict(test_wtRT)\n",
        "# # probasSVM_wtRT = svm.predict_proba(test_wtRT)\n",
        "\n",
        "# # # SVM sigmoid _wtRT\n",
        "# # svmS_wtRT = SVC(kernel='sigmoid',probability=True)\n",
        "# # svmS_wtRT.fit(train_wtRT, target_wtRT)\n",
        "# # predictedSVMS_wtRT = svmS_wtRT.predict(test_wtRT)\n",
        "# # probasSVMS_wtRT = svmS_wtRT.predict_proba(test_wtRT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfPcv-qZ3k4y"
      },
      "outputs": [],
      "source": [
        "# # SVM linear\n",
        "# svm = SVC()\n",
        "# svm.fit(train, target)\n",
        "# predictedSVM = svm.predict(test)\n",
        "# # probasSVM = svm.predict_proba(test)\n",
        "\n",
        "# # SVM sigmoid\n",
        "# svmS = SVC(kernel='sigmoid')\n",
        "# svmS.fit(train, target)\n",
        "# predictedSVMS = svmS.predict(test)\n",
        "# # probasSVMS = svmS.predict_proba(test)\n",
        "\n",
        "# # SVM linear _wtRT\n",
        "# svm_wtRT = SVC()\n",
        "# svm_wtRT.fit(train_wtRT, target_wtRT)\n",
        "# predictedSVM_wtRT = svm_wtRT.predict(test_wtRT)\n",
        "# # probasSVM_wtRT = svm_wtRT.predict_proba(test_wtRT)\n",
        "\n",
        "# # SVM sigmoid _wtRT\n",
        "# svmS_wtRT = SVC(kernel='sigmoid')\n",
        "# svmS_wtRT.fit(train_wtRT, target_wtRT)\n",
        "# predictedSVMS_wtRT = svmS_wtRT.predict(test_wtRT)\n",
        "# # probasSVMS_wtRT = svmS_wtRT.predict_proba(test_wtRT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLFeoOQOuDDS"
      },
      "outputs": [],
      "source": [
        "# svmL = SVC(kernel='linear')\n",
        "# svmL.fit(train, target)\n",
        "# predictedSVML = svmL.predict(test)\n",
        "\n",
        "# # SVM linear _wtRT\n",
        "# svmL_wtRT = SVC(kernel='linear')\n",
        "# svmL_wtRT.fit(train_wtRT, target_wtRT)\n",
        "# predictedSVML_wtRT = svmL_wtRT.predict(test_wtRT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HZeD4--Gz5G"
      },
      "source": [
        "### Performances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdqOk2u_DFa8"
      },
      "source": [
        "\n",
        "\n",
        "> KNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vb0L9ABDFa-"
      },
      "outputs": [],
      "source": [
        "# precisionknn = precision_score(trueResult, predictedknn)\n",
        "# recallknn = recall_score(trueResult, predictedknn)\n",
        "# # fmeasureknn  = f1_score(trueResult, predictedknn)\n",
        "# fprknn , tprknn , thresholdsknn = roc_curve(trueResult, predictedknn)\n",
        "# rocknn  = metrics.auc(fprknn , tprknn )\n",
        "# print(\"Precision: %0.4f\" % precisionknn)\n",
        "# print(\"Recall: %0.4f\" % recallknn)\n",
        "# # print(\"F-mesure: %0.4f\" % fmeasureknn)\n",
        "# print(\"Surface sous la courbe ROC: %0.4f\" % rocknn)\n",
        "# skplt.metrics.plot_confusion_matrix(trueResult, predictedknn, normalize=True)\n",
        "# skplt.metrics.plot_roc(trueResult, probasknn)\n",
        "# skplt.metrics.plot_precision_recall(trueResult, probasknn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qe8eVHgTDn8s"
      },
      "outputs": [],
      "source": [
        "# precisionknn_wtRT = precision_score(trueResult_wtRT, predictedknn_wtRT)\n",
        "# recallknn_wtRT = recall_score(trueResult_wtRT, predictedknn_wtRT)\n",
        "# # fmeasureknn_wtRT  = f1_score(trueResult_wtRT, predictedknn_wtRT)\n",
        "# fprknn_wtRT , tprknn_wtRT , thresholdsknn_wtRT = roc_curve(trueResult_wtRT, predictedknn_wtRT)\n",
        "# rocknn_wtRT  = metrics.auc(fprknn_wtRT , tprknn_wtRT )\n",
        "# print(\"Precision: %0.4f\" % precisionknn_wtRT)\n",
        "# print(\"Recall: %0.4f\" % recallknn_wtRT)\n",
        "# # print(\"F-mesure: %0.4f\" % fmeasureknn_wtRT)\n",
        "# print(\"Surface sous la courbe ROC: %0.4f\" % rocknn_wtRT)\n",
        "# skplt.metrics.plot_confusion_matrix(trueResult_wtRT, predictedknn_wtRT, normalize=True)\n",
        "# # skplt.metrics.plot_roc(trueResult_wtRT, probasknn_wtRT)\n",
        "# # skplt.metrics.plot_precision_recall(trueResult_wtRT, probasKnn_wtRT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq4QAhZfG5zN"
      },
      "source": [
        "\n",
        "\n",
        "> Arbre de décision\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkVYojYwG-6M"
      },
      "outputs": [],
      "source": [
        "# precisionAD = precision_score(trueResult, predictedAD)\n",
        "# recallAD = recall_score(trueResult, predictedAD)\n",
        "# fmeasureAD = f1_score(trueResult, predictedAD)\n",
        "# fprAD, tprAD, thresholdsAD = roc_curve(trueResult, predictedAD)\n",
        "# rocAD = metrics.auc(fprAD, tprAD)\n",
        "# print(\"Precision: %0.4f\" % precisionAD)\n",
        "# print(\"Recall: %0.4f\" % recallAD)\n",
        "# print(\"F-mesure: %0.4f\" % fmeasureAD)\n",
        "# print(\"Surface sous la courbe ROC: %0.4f\" % rocAD)\n",
        "# skplt.metrics.plot_confusion_matrix(trueResult, predictedAD, normalize=True)\n",
        "# skplt.metrics.plot_roc(trueResult, probasAD)\n",
        "# skplt.metrics.plot_precision_recall(trueResult, probasAD)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inoDm0P1Wm2Y"
      },
      "source": [
        "\n",
        "\n",
        "> Arbre de décision _wtRT \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7Sm6Y9LWm2b"
      },
      "outputs": [],
      "source": [
        "# precisionAD_wtRT  = precision_score(trueResult_wtRT , predictedAD_wtRT )\n",
        "# recallAD_wtRT  = recall_score(trueResult_wtRT , predictedAD_wtRT )\n",
        "# fmeasureAD_wtRT  = f1_score(trueResult_wtRT , predictedAD_wtRT )\n",
        "# fprAD_wtRT , tprAD_wtRT , thresholdsAD_wtRT  = roc_curve(trueResult_wtRT , predictedAD_wtRT )\n",
        "# rocAD_wtRT = metrics.auc(fprAD_wtRT , tprAD_wtRT )\n",
        "# print(\"Precision_wtRT : %0.4f\" % precisionAD_wtRT )\n",
        "# print(\"Recall_wtRT : %0.4f\" % recallAD_wtRT )\n",
        "# print(\"F-mesure_wtRT : %0.4f\" % fmeasureAD_wtRT )\n",
        "# print(\"Surface sous la courbe ROC_wtRT : %0.4f\" % rocAD_wtRT )\n",
        "# skplt.metrics.plot_confusion_matrix(trueResult_wtRT , predictedAD_wtRT , normalize=True)\n",
        "# skplt.metrics.plot_roc(trueResult_wtRT , probasAD_wtRT )\n",
        "# skplt.metrics.plot_precision_recall(trueResult_wtRT , probasAD_wtRT )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kfj6s92KJ-X4"
      },
      "source": [
        "\n",
        "\n",
        "> Random Forest\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lx4-2jh2KmMU"
      },
      "outputs": [],
      "source": [
        "# precisionRF = precision_score(trueResult, predictedRF)\n",
        "# recallRF = recall_score(trueResult, predictedRF)\n",
        "# fmeasureRF = f1_score(trueResult, predictedRF)\n",
        "# fprRF, tprRF, thresholdsRF = roc_curve(trueResult, predictedRF)\n",
        "# rocRF = metrics.auc(fprRF, tprRF)\n",
        "# print(\"Precision: %0.4f\" % precisionRF)\n",
        "# print(\"Recall: %0.4f\" % recallRF)\n",
        "# print(\"F-mesure: %0.4f\" % fmeasureRF)\n",
        "# print(\"Surface sous la courbe ROC: %0.4f\" % rocRF)\n",
        "# skplt.metrics.plot_confusion_matrix(trueResult, predictedRF, normalize=True)\n",
        "# skplt.metrics.plot_roc(trueResult, probasRF)\n",
        "# skplt.metrics.plot_precision_recall(trueResult, probasRF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCmXBESJ6b6V"
      },
      "source": [
        "\n",
        "> Random Forest _wtrt_wtRT\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOXZUtpk6b6W"
      },
      "outputs": [],
      "source": [
        "# precisionRF_wtRT = precision_score(trueResult_wtRT, predictedRF_wtRT)\n",
        "# recallRF_wtRT = recall_score(trueResult_wtRT, predictedRF_wtRT)\n",
        "# fmeasureRF_wtRT = f1_score(trueResult_wtRT, predictedRF_wtRT)\n",
        "# fprRF_wtRT, tprRF_wtRT, thresholdsRF_wtRT = roc_curve(trueResult_wtRT, predictedRF_wtRT)\n",
        "# rocRF_wtRT = metrics.auc(fprRF_wtRT, tprRF_wtRT)\n",
        "# print(\"Precision_wtRT: %0.4f\" % precisionRF_wtRT)\n",
        "# print(\"Recall_wtRT: %0.4f\" % recallRF_wtRT)\n",
        "# print(\"F-mesure_wtRT: %0.4f\" % fmeasureRF_wtRT)\n",
        "# print(\"Surface sous la courbe ROC_wtRT: %0.4f\" % rocRF_wtRT)\n",
        "# skplt.metrics.plot_confusion_matrix(trueResult_wtRT, predictedRF_wtRT, normalize=True)\n",
        "# skplt.metrics.plot_roc(trueResult_wtRT, probasRF_wtRT)\n",
        "# skplt.metrics.plot_precision_recall(trueResult_wtRT, probasRF_wtRT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYmOpTAzK77i"
      },
      "source": [
        "\n",
        "\n",
        ">Classification bayésienne naïve\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrsXS3NMK8HJ"
      },
      "outputs": [],
      "source": [
        "# precisionNB = precision_score(trueResult, predictedNB)\n",
        "# recallNB = recall_score(trueResult, predictedNB)\n",
        "# fmeasureNB = f1_score(trueResult, predictedNB)\n",
        "# fprNB, tprNB, thresholdsNB = roc_curve(trueResult, predictedNB)\n",
        "# rocNB = metrics.roc_auc_score(trueResult, predictedNB)\n",
        "# print(\"Precision: %0.4f\" % precisionNB)\n",
        "# print(\"Recall: %0.4f\" % recallNB)\n",
        "# print(\"F-mesure: %0.4f\" % fmeasureNB)\n",
        "# print(\"Surface sous la courbe ROC: %0.4f\" % rocNB)\n",
        "# skplt.metrics.plot_confusion_matrix(trueResult, predictedNB, normalize=True)\n",
        "# skplt.metrics.plot_roc(trueResult, probasNB)\n",
        "# skplt.metrics.plot_precision_recall(trueResult, probasNB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON1Nfgk47IK3"
      },
      "source": [
        "\n",
        "\n",
        ">Classification bayésienne naïve _wtRT\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tA3aCBCq7IK5"
      },
      "outputs": [],
      "source": [
        "# precisionNB_wtRT = precision_score(trueResult_wtRT, predictedNB_wtRT)\n",
        "# recallNB_wtRT = recall_score(trueResult_wtRT, predictedNB_wtRT)\n",
        "# fmeasureNB_wtRT = f1_score(trueResult_wtRT, predictedNB_wtRT)\n",
        "# fprNB_wtRT, tprNB_wtRT, thresholdsNB_wtRT = roc_curve(trueResult_wtRT, predictedNB_wtRT)\n",
        "# rocNB_wtRT = metrics.roc_auc_score(trueResult_wtRT, predictedNB_wtRT)\n",
        "# print(\"Precision_wtRT: %0.4f\" % precisionNB_wtRT)\n",
        "# print(\"Recall_wtRT: %0.4f\" % recallNB_wtRT)\n",
        "# print(\"F-mesure_wtRT: %0.4f\" % fmeasureNB_wtRT)\n",
        "# print(\"Surface sous la courbe ROC: %0.4f\" % rocNB_wtRT)\n",
        "# skplt.metrics.plot_confusion_matrix(trueResult_wtRT, predictedNB_wtRT, normalize=True)\n",
        "# skplt.metrics.plot_roc(trueResult_wtRT, probasNB_wtRT)\n",
        "# skplt.metrics.plot_precision_recall(trueResult_wtRT, probasNB_wtRT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKZbrQ0XEKXZ"
      },
      "outputs": [],
      "source": [
        "# print(trueResult.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VC9j_HP_8pmV"
      },
      "source": [
        "SVM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sz4R-JMX4OcZ"
      },
      "outputs": [],
      "source": [
        "# precisionSVM = precision_score(trueResult, predictedSVM)\n",
        "# recallSVM = recall_score(trueResult, predictedSVM)\n",
        "# fmeasureSVM = f1_score(trueResult, predictedSVM)\n",
        "# fprSVM, tprSVM, thresholdsSVM = roc_curve(trueResult, predictedSVM)\n",
        "# rocSVM = metrics.auc(fprSVM, tprSVM)\n",
        "# print(\"Precision: %0.4f\" % precisionSVM)\n",
        "# print(\"Recall: %0.4f\" % recallSVM)\n",
        "# print(\"F-mesure: %0.4f\" % fmeasureSVM)\n",
        "# print(\"Surface sous la courbe ROC: %0.4f\" % rocSVM)\n",
        "# skplt.metrics.plot_confusion_matrix(trueResult, predictedSVM, normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tDA_UqG8rga"
      },
      "outputs": [],
      "source": [
        "# precisionSVM_wtRT = precision_score(trueResult_wtRT, predictedSVM_wtRT)\n",
        "# recallSVM_wtRT = recall_score(trueResult_wtRT, predictedSVM_wtRT)\n",
        "# fmeasureSVM_wtRT = f1_score(trueResult_wtRT, predictedSVM_wtRT)\n",
        "# fprSVM_wtRT, tprSVM_wtRT, thresholdsSVM_wtRT = roc_curve(trueResult_wtRT, predictedSVM_wtRT)\n",
        "# rocSVM_wtRT = metrics.auc(fprSVM_wtRT, tprSVM_wtRT)\n",
        "# print(\"Precision_wtRT: %0.4f\" % precisionSVM_wtRT)\n",
        "# print(\"Recall_wtRT: %0.4f\" % recallSVM_wtRT)\n",
        "# print(\"F-mesure_wtRT: %0.4f\" % fmeasureSVM_wtRT)\n",
        "# print(\"Surface sous la courbe ROC_wtRT: %0.4f\" % rocSVM_wtRT)\n",
        "# skplt.metrics.plot_confusion_matrix(trueResult_wtRT, predictedSVM_wtRT, normalize=True)\n",
        "# # skplt.metrics.plot_roc(trueResult, probasSVM)\n",
        "# # skplt.metrics.plot_precision_recall(trueResult, probasSVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAa2-HSEuZ4K"
      },
      "outputs": [],
      "source": [
        "# precisionSVML = precision_score(trueResult, predictedSVML)\n",
        "# recallSVML = recall_score(trueResult, predictedSVML)\n",
        "# fmeasureSVML = f1_score(trueResult, predictedSVML)\n",
        "# fprSVML, tprSVML, thresholdsSVML = roc_curve(trueResult, predictedSVML)\n",
        "# rocSVML = metrics.auc(fprSVML, tprSVML)\n",
        "# print(\"Precision: %0.4f\" % precisionSVML)\n",
        "# print(\"Recall: %0.4f\" % recallSVML)\n",
        "# print(\"F-mesure: %0.4f\" % fmeasureSVML)\n",
        "# print(\"Surface sous la courbe ROC: %0.4f\" % rocSVML)\n",
        "# skplt.metrics.plot_confusion_matrix(trueResult, predictedSVML, normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQlhNxaeu5_y"
      },
      "outputs": [],
      "source": [
        "# precisionSVML_wtRT = precision_score(trueResult_wtRT, predictedSVML_wtRT)\n",
        "# recallSVML_wtRT = recall_score(trueResult_wtRT, predictedSVML_wtRT)\n",
        "# fmeasureSVML_wtRT = f1_score(trueResult_wtRT, predictedSVML_wtRT)\n",
        "# # fprSVM_wtRT, tprSVM_wtRT, thresholdsSVM_wtRT = roc_curve(trueResult_wtRT, predictedSVML_wtRT)\n",
        "# # rocSVM_wtRT = metrics.auc(fprSVM_wtRT, tprSVM_wtRT)\n",
        "# print(\"Precision_wtRT: %0.4f\" % precisionSVML_wtRT)\n",
        "# print(\"Recall_wtRT: %0.4f\" % recallSVML_wtRT)\n",
        "# print(\"F-mesure_wtRT: %0.4f\" % fmeasureSVML_wtRT)\n",
        "# # print(\"Surface sous la courbe ROC_wtRT: %0.4f\" % rocSVM_wtRT)\n",
        "# skplt.metrics.plot_confusion_matrix(trueResult_wtRT, predictedSVML_wtRT, normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXznmJ6-AgaV"
      },
      "source": [
        "# SVM sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qI0CX-kL31qg"
      },
      "outputs": [],
      "source": [
        "# precisionSVM = precision_score(trueResult, predictedSVMS)\n",
        "# recallSVM = recall_score(trueResult, predictedSVMS)\n",
        "# fmeasureSVM = f1_score(trueResult, predictedSVMS)\n",
        "# fprSVM, tprSVM, thresholdsSVM = roc_curve(trueResult, predictedSVMS)\n",
        "# rocSVM = metrics.auc(fprSVM, tprSVM)\n",
        "# print(\"Precision: %0.4f\" % precisionSVM)\n",
        "# print(\"Recall: %0.4f\" % recallSVM)\n",
        "# print(\"F-mesure: %0.4f\" % fmeasureSVM)\n",
        "# print(\"Surface sous la courbe ROC: %0.4f\" % rocSVM)\n",
        "# skplt.metrics.plot_confusion_matrix(trueResult, predictedSVMS, normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHyoyVeaA38D"
      },
      "outputs": [],
      "source": [
        "# precisionSVM_wtRT = precision_score(trueResult_wtRT, predictedSVMS_wtRT)\n",
        "# recallSVM_wtRT = recall_score(trueResult_wtRT, predictedSVMS_wtRT)\n",
        "# fmeasureSVM_wtRT = f1_score(trueResult_wtRT, predictedSVMS_wtRT)\n",
        "# fprSVM_wtRT, tprSVM_wtRT, thresholdsSVM_wtRT = roc_curve(trueResult_wtRT, predictedSVMS_wtRT)\n",
        "# rocSVM = metrics.auc(fprSVM, tprSVM)\n",
        "# print(\"Precision_wtRT: %0.4f\" % precisionSVM_wtRT)\n",
        "# print(\"Recall_wtRT: %0.4f\" % recallSVM_wtRT)\n",
        "# print(\"F-mesure_wtRT: %0.4f\" % fmeasureSVM_wtRT)\n",
        "# print(\"Surface sous la courbe ROC: %0.4f\" % rocSVM_wtRT)\n",
        "# skplt.metrics.plot_confusion_matrix(trueResult_wtRT, predictedSVMS_wtRT, normalize=True)\n",
        "# # skplt.metrics.plot_roc(trueResult, probasSVM)\n",
        "# # skplt.metrics.plot_precision_recall(trueResult, probasSVMS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21tG_3Q-p7G4"
      },
      "outputs": [],
      "source": [
        "from sklearn import model_selection\n",
        "from sklearn.metrics import classification_report,confusion_matrix,make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3TDmihkrO3m"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "seed = 6\n",
        "# scoring ='accuracy'\n",
        "\n",
        "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
        "           'precision' : make_scorer(precision_score),\n",
        "           'recall' : make_scorer(recall_score), \n",
        "           'f1_score' : make_scorer(f1_score)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hlva0Vi_M8Pz"
      },
      "outputs": [],
      "source": [
        "# # With Out Rewteet faeture\n",
        "# models = []\n",
        "# models.append(('LR',LogisticRegression()))             #Logistic Regression\n",
        "# models.append(('MLP',MLPClassifier(hidden_layer_sizes=(15,15))))             #Logistic Regression\n",
        "# models.append(('LDA',LinearDiscriminantAnalysis()))    #Linear Discrimant Analysis\n",
        "# models.append(('KNN|IBK',KNeighborsClassifier(n_neighbors=5)))          #K-NearestNeighbor Classifier\n",
        "# models.append(('CART|J48',DecisionTreeClassifier()))       #Decision Tree Classifier \n",
        "# models.append(('RF',RandomForestClassifier(n_estimators=100)))       #Random Forest Classifier \n",
        "# models.append(('NB',GaussianNB()))                     #Naive Bayes\n",
        "# models.append(('SVM',SVC()))                           #Support Vector Machine\n",
        "# results = []\n",
        "# names = []\n",
        "# for name,model in models:\n",
        "#     kfold = model_selection.KFold(n_splits=10,shuffle= False)\n",
        "#     cv_results = model_selection.cross_validate(model,train_wtRT ,target_wtRT,cv=kfold, scoring= scoring)\n",
        "#     results.append(cv_results)\n",
        "#     names.append(name)\n",
        "#     precision = '%s precision: %f (%f)' % (name, cv_results['test_precision'].mean()*100, cv_results['test_precision'].std())\n",
        "#     recall = '%s recall: %f (%f)' % (name, cv_results['test_recall'].mean()*100, cv_results['test_recall'].std())\n",
        "#     f1_score = '%s f1_score: %f (%f)' % (name, cv_results['test_f1_score'].mean()*100, cv_results['test_f1_score'].std())\n",
        "#     print(precision)\n",
        "#     print(recall)\n",
        "#     print(f1_score)\n",
        "# # dict_keys(['fit_time', 'score_time', 'test_accuracy', 'test_precision', 'test_recall', 'test_f1_score'])\n",
        "# # cross_validate or cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zONJPZTgvukk",
        "outputId": "c394167d-ba37-476a-99da-2d88d740c50f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "precision :  LR precision: 89.707543 (0.015503)\n",
            "recall :  LR recall: 86.024100 (0.012269)\n",
            "f1_score :  LR f1_score: 87.811211 (0.007158)\n",
            "accuracy :  LR f1_score: 87.252568 (0.007828)\n",
            "precision :  MLP precision: 88.583116 (0.035310)\n",
            "recall :  MLP recall: 90.367006 (0.054319)\n",
            "f1_score :  MLP f1_score: 89.245261 (0.014427)\n",
            "accuracy :  MLP f1_score: 88.440240 (0.010604)\n",
            "precision :  LDA precision: 83.996167 (0.005925)\n",
            "recall :  LDA recall: 74.520172 (0.012748)\n",
            "f1_score :  LDA f1_score: 78.970661 (0.008793)\n",
            "accuracy :  LDA f1_score: 78.825456 (0.007175)\n",
            "precision :  KNN5|IBK precision: 90.765659 (0.006150)\n",
            "recall :  KNN5|IBK recall: 89.603863 (0.009773)\n",
            "f1_score :  KNN5|IBK f1_score: 90.179987 (0.007593)\n",
            "accuracy :  KNN5|IBK f1_score: 89.589983 (0.007409)\n",
            "precision :  KNN10|IBK precision: 91.742455 (0.006144)\n",
            "recall :  KNN10|IBK recall: 87.862459 (0.008911)\n",
            "f1_score :  KNN10|IBK f1_score: 89.758977 (0.006746)\n",
            "accuracy :  KNN10|IBK f1_score: 89.304258 (0.006304)\n",
            "precision :  KNN15|IBK precision: 90.993740 (0.006946)\n",
            "recall :  KNN15|IBK recall: 88.806143 (0.007562)\n",
            "f1_score :  KNN15|IBK f1_score: 89.884911 (0.006093)\n",
            "accuracy :  KNN15|IBK f1_score: 89.335255 (0.005989)\n",
            "precision :  CART|J48 precision: 90.913728 (0.006772)\n",
            "recall :  CART|J48 recall: 90.957963 (0.006484)\n",
            "f1_score :  CART|J48 f1_score: 90.935279 (0.006234)\n",
            "accuracy :  CART|J48 f1_score: 90.326647 (0.005858)\n",
            "precision :  RF precision: 93.860359 (0.005505)\n",
            "recall :  RF recall: 94.658141 (0.002828)\n",
            "f1_score :  RF f1_score: 94.257039 (0.003787)\n",
            "accuracy :  RF f1_score: 93.844850 (0.003826)\n",
            "precision :  NB precision: 93.968524 (0.029997)\n",
            "recall :  NB recall: 26.466405 (0.173338)\n",
            "f1_score :  NB f1_score: 38.734453 (0.148316)\n",
            "accuracy :  NB f1_score: 59.585346 (0.072244)\n",
            "precision :  SVM precision: 91.132982 (0.005752)\n",
            "recall :  SVM recall: 73.742146 (0.010304)\n",
            "f1_score :  SVM f1_score: 81.516058 (0.006907)\n",
            "accuracy :  SVM f1_score: 82.154301 (0.006056)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#USING CROSS VALIDATION TO ESTIMATE THE BEST ALGOTRITHM \n",
        "models = []\n",
        "models.append(('LR',LogisticRegression()))             #Logistic Regression\n",
        "models.append(('MLP',MLPClassifier(hidden_layer_sizes=(15,15))))             #Logistic Regression\n",
        "models.append(('LDA',LinearDiscriminantAnalysis()))    #Linear Discrimant Analysis\n",
        "models.append(('KNN5|IBK',KNeighborsClassifier(n_neighbors=5)))          #K-NearestNeighbor Classifier\n",
        "models.append(('KNN10|IBK',KNeighborsClassifier(n_neighbors=10)))          #K-NearestNeighbor Classifier\n",
        "models.append(('KNN15|IBK',KNeighborsClassifier(n_neighbors=15)))          #K-NearestNeighbor Classifier\n",
        "models.append(('CART|J48',DecisionTreeClassifier()))       #Decision Tree Classifier \n",
        "models.append(('RF',RandomForestClassifier(n_estimators=100)))       #Random Forest Classifier \n",
        "models.append(('NB',GaussianNB()))                     #Naive Bayes\n",
        "models.append(('SVM',SVC()))                           #Support Vector Machine\n",
        "results = []\n",
        "names = []\n",
        "for name,model in models:\n",
        "    kfold = model_selection.KFold(n_splits=10,shuffle= False)\n",
        "    cv_results = model_selection.cross_validate(model,train ,target,cv=kfold, scoring= scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    precision = '%s precision: %f (%f)' % (name, cv_results['test_precision'].mean()*100, cv_results['test_precision'].std())\n",
        "    recall = '%s recall: %f (%f)' % (name, cv_results['test_recall'].mean()*100, cv_results['test_recall'].std())\n",
        "    f1_score = '%s f1_score: %f (%f)' % (name, cv_results['test_f1_score'].mean()*100, cv_results['test_f1_score'].std())\n",
        "    accuracy = '%s f1_score: %f (%f)' % (name, cv_results['test_accuracy'].mean()*100, cv_results['test_accuracy'].std())\n",
        "    print(\"precision : \",precision)\n",
        "    print(\"recall : \",recall)\n",
        "    print(\"f1_score : \",f1_score)\n",
        "    print(\"accuracy : \", accuracy)\n",
        "# dict_keys(['fit_time', 'score_time', 'test_accuracy', 'test_precision', 'test_recall', 'test_f1_score'])\n",
        "# cross_validate or cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkNlypNuWWoh"
      },
      "outputs": [],
      "source": [
        "# # With Out Rewteet faeture\n",
        "# models = []\n",
        "# models.append(('LR',LogisticRegression()))             #Logistic Regression\n",
        "# models.append(('LDA',LinearDiscriminantAnalysis()))    #Linear Discrimant Analysis\n",
        "# models.append(('KNN|IBK',KNeighborsClassifier(n_neighbors=5)))          #K-NearestNeighbor Classifier\n",
        "# models.append(('CART|J48',DecisionTreeClassifier()))       #Decision Tree Classifier \n",
        "# models.append(('RF',RandomForestClassifier(n_estimators=100)))       #Random Forest Classifier \n",
        "# models.append(('NB',GaussianNB()))                     #Naive Bayes\n",
        "# models.append(('SVM',SVC()))                           #Support Vector Machine\n",
        "# results = []\n",
        "# names = []\n",
        "# for name,model in models:\n",
        "#     kfold = model_selection.KFold(n_splits=10,random_state=seed,shuffle= True)\n",
        "#     cv_results = model_selection.cross_validate(model,train_wtRT ,target_wtRT,cv=kfold, scoring= scoring)\n",
        "#     results.append(cv_results)\n",
        "#     names.append(name)\n",
        "#     precision = '%s precision: %f (%f)' % (name, cv_results['test_precision'].mean()*100, cv_results['test_precision'].std())\n",
        "#     recall = '%s recall: %f (%f)' % (name, cv_results['test_recall'].mean()*100, cv_results['test_recall'].std())\n",
        "#     f1_score = '%s f1_score: %f (%f)' % (name, cv_results['test_f1_score'].mean()*100, cv_results['test_f1_score'].std())\n",
        "#     print(precision)\n",
        "#     print(recall)\n",
        "#     print(f1_score)\n",
        "# # dict_keys(['fit_time', 'score_time', 'test_accuracy', 'test_precision', 'test_recall', 'test_f1_score'])\n",
        "# # cross_validate or cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "oto7mPx1EUEx",
        "outputId": "4cf0b260-649e-4712-b913-9fe91aaac36c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bd59b1c682d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#USING CROSS VALIDATION TO ESTIMATE THE BEST ALGOTRITHM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LR'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m             \u001b[0;31m#Logistic Regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MLP'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m             \u001b[0;31m#Logistic Regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LDA'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLinearDiscriminantAnalysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m#Linear Discrimant Analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
          ]
        }
      ],
      "source": [
        "#USING CROSS VALIDATION TO ESTIMATE THE BEST ALGOTRITHM \n",
        "models = []\n",
        "models.append(('LR',LogisticRegression()))             #Logistic Regression\n",
        "models.append(('MLP',MLPClassifier(hidden_layer_sizes=(15,15))))             #Logistic Regression\n",
        "models.append(('LDA',LinearDiscriminantAnalysis()))    #Linear Discrimant Analysis\n",
        "models.append(('KNN5',KNeighborsClassifier()))          #K-NearestNeighbor Classifier\n",
        "models.append(('KNN10|IBK',KNeighborsClassifier(n_neighbors=10)))          #K-NearestNeighbor Classifier\n",
        "models.append(('KNN15|IBK',KNeighborsClassifier(n_neighbors=15)))          #K-NearestNeighbor Classifier\n",
        "models.append(('CART',DecisionTreeClassifier()))       #Decision Tree Classifier \n",
        "models.append(('RF',RandomForestClassifier(n_estimators=100)))       #Random Forest Classifier \n",
        "models.append(('NB',GaussianNB()))                     #Naive Bayes\n",
        "models.append(('SVM',SVC()))                           #Support Vector Machine\n",
        "results = []\n",
        "names = []\n",
        "for name,model in models:\n",
        "    kfold = model_selection.KFold(n_splits=10,random_state=seed,shuffle= True)\n",
        "    cv_results = model_selection.cross_validate(model,train ,target,cv=kfold, scoring= scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    precision = '%s precision: %f (%f)' % (name, cv_results['test_precision'].mean()*100, cv_results['test_precision'].std())\n",
        "    recall = '%s recall: %f (%f)' % (name, cv_results['test_recall'].mean()*100, cv_results['test_recall'].std())\n",
        "    f1_score = '%s f1_score: %f (%f)' % (name, cv_results['test_f1_score'].mean()*100, cv_results['test_f1_score'].std())\n",
        "    accuracy = '%s f1_score: %f (%f)' % (name, cv_results['test_accuracy'].mean()*100, cv_results['test_accuracy'].std())\n",
        "    print(\"precision : \",precision)\n",
        "    print(\"recall : \",recall)\n",
        "    print(\"f1_score : \",f1_score)\n",
        "    print(\"accuracy : \", accuracy)\n",
        "# dict_keys(['fit_time', 'score_time', 'test_accuracy', 'test_precision', 'test_recall', 'test_f1_score'])\n",
        "# cross_validate or cross_val_score"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}